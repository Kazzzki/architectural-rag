import patch_importlib  # æœ€å„ªå…ˆã§å®Ÿè¡Œ
import os
import sys
# ä»¥å‰ã®ãƒ‘ãƒƒãƒã¯ patch_importlib.py ã«ç§»å‹•ã—ãŸã®ã§å‰Šé™¤
# (é‡è¤‡ã—ã¦ã‚‚å•é¡Œãªã„ãŒã‚­ãƒ¬ã‚¤ã«ã™ã‚‹)

import shutil
import time
from pathlib import Path
from typing import Optional, List
from datetime import datetime
import logging

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, RedirectResponse, FileResponse, JSONResponse
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from pydantic import BaseModel
import secrets
# Logging setup (Phase 3)
logging.basicConfig(
    filename='app.log',
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    encoding='utf-8'
)
# Console handler
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

logger = logging.getLogger(__name__)

from config import (
    CORS_ORIGINS,
    KNOWLEDGE_BASE_DIR,
    SUPPORTED_EXTENSIONS,
    GEMINI_API_KEY,
)
from retriever import search, build_context, get_source_files, get_db_stats
from generator import generate_answer, generate_answer_stream
from ocr_processor import process_pdf_background
from indexer import build_index, scan_files

import gemini_client  # å…±æœ‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–

# Basicèªè¨¼è¨­å®šï¼ˆãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã§å…¨APIä¿è­·ï¼‰
APP_PASSWORD = os.environ.get("APP_PASSWORD", "")

if APP_PASSWORD:
    import base64
    from starlette.middleware.base import BaseHTTPMiddleware
    from starlette.responses import Response

    class BasicAuthMiddleware(BaseHTTPMiddleware):
        """APP_PASSWORDè¨­å®šæ™‚ã«å…¨APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’Basicèªè¨¼ã§ä¿è­·"""
        # èªè¨¼ä¸è¦ã®ãƒ‘ã‚¹
        EXEMPT_PATHS = {"/api/health", "/docs", "/openapi.json"}

        async def dispatch(self, request, call_next):
            path = request.url.path

            # èªè¨¼ä¸è¦ãƒ‘ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
            if path in self.EXEMPT_PATHS:
                return await call_next(request)

            # OPTIONSãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆCORSãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
            if request.method == "OPTIONS":
                return await call_next(request)

            # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»éAPIãƒ‘ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
            if not path.startswith("/api/"):
                return await call_next(request)

            # Authorization ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œè¨¼
            auth = request.headers.get("Authorization")
            authenticated = False
            if auth and auth.startswith("Basic "):
                try:
                    decoded = base64.b64decode(auth[6:]).decode("utf-8")
                    _, password = decoded.split(":", 1)
                    if secrets.compare_digest(password, APP_PASSWORD):
                        authenticated = True
                except Exception:
                    pass
            
            if authenticated:
                return await call_next(request)

            return Response(
                content="èªè¨¼ãŒå¿…è¦ã§ã™",
                status_code=401,
                headers={"WWW-Authenticate": 'Basic realm="Antigravity RAG"'},
            )

    print("ğŸ”’ Basicèªè¨¼ãŒæœ‰åŠ¹ã§ã™ (APP_PASSWORDè¨­å®šæ¸ˆ)")
else:
    print("âš ï¸  APP_PASSWORDãŒæœªè¨­å®šã®ãŸã‚ã€èªè¨¼ãªã—ã§å‹•ä½œã—ã¾ã™")


app = FastAPI(
    title="å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸RAG API",
    description="å»ºç¯‰PM/CMæ¥­å‹™å‘ã‘ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ãƒ»å›ç­”ç”ŸæˆAPI",
    version="1.0.0",
)

# èªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’ç™»éŒ²
if APP_PASSWORD:
    app.add_middleware(BasicAuthMiddleware)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
from database import init_db, migrate_from_json
init_db()
# åˆå›èµ·å‹•æ™‚ã«æ—¢å­˜JSONãƒ‡ãƒ¼ã‚¿ã‚’DBã¸ç§»è¡Œ
try:
    migrate_from_json()
except Exception as e:
    print(f"JSON migration skipped or error: {e}")

import threading
@app.on_event("startup")
def startup_event():
    def background_build_index():
        try:
            print("Starting background index build...")
            build_index(force_rebuild=False)
            print("Background index build completed.")
        except Exception as e:
            print(f"Background index build failed: {e}")
            import traceback
            traceback.print_exc()
            
    threading.Thread(target=background_build_index, daemon=True).start()

# ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ãƒã‚¦ãƒ³ãƒˆ
from mindmap.router import router as mindmap_router
app.include_router(mindmap_router)

# Global Exception Handler (Phase 3 -> RAG v2 Update)
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    import traceback
    logger.error(
        f"Unhandled exception: {type(exc).__name__}: {exc}\n"
        f"Path: {request.url.path}\n"
        f"Traceback:\n{traceback.format_exc()}"
    )
    return JSONResponse(
        status_code=500,
        content={"detail": "ã‚µãƒ¼ãƒãƒ¼å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"}
    )

# CORSè¨­å®š (ngrokå¯¾å¿œ)
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,  # config.pyã§å®šç¾©ã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒ³
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class ChatRequest(BaseModel):
    question: str
    category: Optional[str] = None
    file_type: Optional[str] = None
    date_range: Optional[str] = None
    tags: Optional[List[str]] = None
    tag_match_mode: Optional[str] = "any"
    history: Optional[List[dict]] = None  # [{role: "user"|"assistant", content: str}]


class ChatResponse(BaseModel):
    answer: str
    sources: List[dict]


class StatsResponse(BaseModel):
    file_count: int
    chunk_count: int
    last_updated: str


class IndexResponse(BaseModel):
    total_files: int
    indexed: int
    skipped: int
    errors: int
    chunks: int


class FileInfo(BaseModel):
    filename: str
    category: str
    size_kb: float
    uploaded_at: str


# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    return {"message": "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸RAG API", "status": "running"}


@app.get("/api/health")
async def health_check():
    """
    å¤–å½¢ç›£è¦–ç”¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã€‚
    ChromaDBãƒ»SQLiteãƒ»Gemini APIãƒ»Google Driveãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç–é€šã‚’ç¢ºèªã™ã‚‹ã€‚
    """
    from datetime import datetime as _dt

    status = {
        "server": "ok",
        "chromadb": "unknown",
        "sqlite": "unknown",
        "gemini_api": "unknown",
        "google_drive": "unknown",
        "file_storage": "unknown",
    }

    # 1. ChromaDBç¢ºèª
    from retriever import get_collection
    try:
        collection = get_collection()
        count = collection.count()
        status["chromadb"] = f"ok ({count} chunks)"
    except Exception as e:
        status["chromadb"] = f"error: {e}"

    # 2. SQLiteç¢ºèª
    from database import get_session
    try:
        session = get_session()
        from sqlalchemy import text
        session.execute(text("SELECT 1"))
        session.close()
        status["sqlite"] = "ok"
    except Exception as e:
        status["sqlite"] = f"error: {e}"

    # 3. Gemini APIç¢ºèªï¼ˆè»½é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
    try:
        from gemini_client import get_client
        from config import EMBEDDING_MODEL
        client = get_client()
        client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents='ping'
        )
        status["gemini_api"] = "ok"
    except Exception as e:
        status["gemini_api"] = f"error: {e}"

    # 4. Google Driveèªè¨¼ç¢ºèª
    try:
        from drive_sync import get_auth_status
        drive_info = get_auth_status()
        if drive_info.get("authenticated"):
            status["google_drive"] = "ok"
        else:
            status["google_drive"] = f"not authenticated: {drive_info.get('message', '')}"
    except Exception as e:
        status["google_drive"] = f"error: {e}"

    # 5. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç¢ºèª
    try:
        from indexer import scan_files
        files = scan_files()
        status["file_storage"] = f"ok ({len(files)} files)"
    except Exception as e:
        status["file_storage"] = f"error: {e}"

    # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
    error_count = sum(1 for v in status.values() if str(v).startswith("error"))
    warn_count = sum(1 for v in status.values() if "not authenticated" in str(v) or v == "unknown")
    if error_count > 0:
        overall = "error"
    elif warn_count > 0:
        overall = "degraded"
    else:
        overall = "ok"

    result = {
        "status": overall,
        "services": status,
        "timestamp": _dt.now().isoformat(),
    }

    all_ok = overall == "ok"
    return JSONResponse(
        content=result,
        status_code=200 if all_ok or overall == "degraded" else 503
    )


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆ"""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    try:
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆã‚¿ã‚°ãƒ»ã‚¿ã‚°ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã‚‚æ¸¡ã™ï¼‰
        search_results = search(
            request.question,
            filter_category=request.category,
            filter_file_type=request.file_type,
            filter_date_range=request.date_range,
            filter_tags=request.tags,
            tag_match_mode=request.tag_match_mode or "any",
        )

        logger.info(f"Query: {request.question}, Results: {len(search_results.get('documents', []))}")

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context = build_context(search_results)

        # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        source_files = get_source_files(search_results)

        # å›ç­”ç”Ÿæˆï¼ˆä¼šè©±å±¥æ­´ã‚’æ¸¡ã™ï¼‰
        answer = generate_answer(request.question, context, source_files, history=request.history)

        logger.info(f"Answer generated ({len(answer)} chars)")

        return ChatResponse(answer=answer, sources=source_files)

    except RuntimeError as e:
        logger.error(f"Gemini APIå®Œå…¨å¤±æ•—: {e}")
        raise HTTPException(
            status_code=503,
            detail=str(e)
        )
    except Exception as e:
        logger.exception(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§å›ç­”ã‚’ç”Ÿæˆ (Phase 2: SSEå¯¾å¿œ)"""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    try:
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆã‚¿ã‚°ãƒ»ã‚¿ã‚°ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã‚‚æ¸¡ã™ï¼‰
        search_results = search(
            request.question,
            filter_category=request.category,
            filter_file_type=request.file_type,
            filter_date_range=request.date_range,
            filter_tags=request.tags,
            tag_match_mode=request.tag_match_mode or "any",
        )
        context = build_context(search_results)
        source_files = get_source_files(search_results)
        history = request.history

        async def generate():
            import json
            # 1. ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å…ˆã«é€ä¿¡
            yield f"data: {json.dumps({'type': 'sources', 'data': source_files}, ensure_ascii=False)}\n\n"

            try:
                # 2. å›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼ˆä¼šè©±å±¥æ­´ã‚’æ¸¡ã™ï¼‰
                async for chunk in generate_answer_stream(request.question, context, source_files, history=history):
                    yield f"data: {json.dumps({'type': 'answer', 'data': chunk}, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.error(f"Stream exception: {e}")
                # ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦é€ä¿¡ã—ã€ãƒ•ãƒ­ãƒ³ãƒˆã§ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
                yield f"event: error\ndata: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"

            # 3. å®Œäº†ã‚·ã‚°ãƒŠãƒ«
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            generate(), 
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            }
        )
        
    except Exception as e:
        logger.error(f"Stream Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/stats", response_model=StatsResponse)
def get_stats():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆã‚’å–å¾—"""
    stats = get_db_stats()
    return StatsResponse(
        file_count=stats["file_count"],
        chunk_count=stats["chunk_count"],
        last_updated=stats["last_updated"] or "æœªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
    )


@app.get("/api/ocr/status")
def get_ocr_status():
    """OCRå‡¦ç†ä¸­ãƒ»æœ€è¿‘å‡¦ç†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¿”ã™"""
    try:
        from database import get_session, Document
        session = get_session()
        try:
            # processingã¾ãŸã¯æœ€è¿‘completedã«ãªã£ãŸã‚‚ã®
            from datetime import datetime, timedelta
            recent_cutoff = datetime.now() - timedelta(minutes=30)
            docs = session.query(Document).filter(
                (Document.status == "processing") |
                (Document.status == "failed") |
                ((Document.status == "completed") & (Document.updated_at >= recent_cutoff))
            ).order_by(Document.updated_at.desc()).limit(20).all()
            
            jobs = []
            for doc in docs:
                jobs.append({
                    "file_path": doc.file_path,
                    "filename": doc.filename,
                    "status": doc.status,
                    "processed_pages": doc.processed_pages or 0,
                    "total_pages": doc.total_pages or 1,
                    "error_message": doc.error_message,
                    "estimated_remaining": doc.estimated_remaining,
                    "updated_at": doc.updated_at.isoformat() if doc.updated_at else None,
                })
            
            processing_count = sum(1 for j in jobs if j["status"] == "processing")
            return {
                "processing_count": processing_count,
                "jobs": jobs
            }
        finally:
            session.close()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/ocr/status/{file_path:path}")
def dismiss_ocr_status(file_path: str):
    """OCRã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆéè¡¨ç¤ºåŒ–ï¼‰"""
    try:
        from status_manager import OCRStatusManager
        OCRStatusManager().remove_status(file_path)
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/index", response_model=IndexResponse)
def rebuild_index(force: bool = False):
    """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰"""
    try:
        stats = build_index(force_rebuild=force)
        return IndexResponse(**stats)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Old upload_file implementation removed to avoid duplicate endpoint


@app.post("/api/upload/multiple")
async def upload_multiple_files(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...)
):
    """Webç”»é¢ã‹ã‚‰è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€file_storeã«ç™»éŒ²ã™ã‚‹"""
    ALLOWED_EXTENSIONS = {".pdf", ".png", ".jpg", ".jpeg", ".md", ".txt"}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    
    from config import BASE_DIR, KNOWLEDGE_BASE_DIR, UNCATEGORIZED_FOLDER
    input_dir = Path(BASE_DIR) / "input"
    input_dir.mkdir(parents=True, exist_ok=True)

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç›´å¾Œã¯æœªåˆ†é¡ãƒ•ã‚©ãƒ«ãƒ€ã¸ï¼ˆOCRå¾Œã«è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªã¸ç§»å‹•ï¼‰
    pdf_dir = Path(KNOWLEDGE_BASE_DIR) / UNCATEGORIZED_FOLDER
    pdf_dir.mkdir(parents=True, exist_ok=True)

    import file_store
    
    results = []
    errors = []
    
    for file in files:
        filename = file.filename or "unknown"
        filename = os.path.basename(filename)
        ext = os.path.splitext(filename)[1].lower()
        
        if ext not in ALLOWED_EXTENSIONS:
            errors.append({"filename": filename, "error": f"Unsupported file type: {ext}"})
            continue
            
        import re
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ä¸Šã§å±é™ºãªæ–‡å­—ã®ã¿é™¤å»ã™ã‚‹
        # werkzeug ã® secure_filename() ã¯æ—¥æœ¬èªã‚’é™¤å»ã—ã¦ã—ã¾ã†ãŸã‚ä½¿ã‚ãªã„
        safe_filename = re.sub(r'[/\\:*?"<>|]', '_', filename).strip()
        # ãƒ‰ãƒƒãƒˆã®ã¿ãƒ»ç©ºãƒ»æ‹¡å¼µå­ã®ã¿ã«ãªã£ãŸå ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not safe_filename or safe_filename == ext or safe_filename.lstrip('.') == '':
            safe_filename = f"file_{int(time.time())}_{len(results)}{ext}"
        if not safe_filename.lower().endswith(ext):
            safe_filename = safe_filename + ext
            
        base_name = Path(safe_filename).stem
        file_path = input_dir / safe_filename
        timestamp = int(time.time())
        if file_path.exists():
            file_path = input_dir / f"{base_name}_{timestamp}_{len(results)}{ext}"
            
        try:
            content = await file.read()
            if len(content) > MAX_FILE_SIZE:
                errors.append({"filename": filename, "error": f"File too large. Maximum size is {MAX_FILE_SIZE // (1024*1024)}MB"})
                continue
                
            content_type = "application/pdf" if ext == ".pdf" else f"image/{ext[1:]}"
            reg = file_store.register_file(
                original_name=filename,
                current_path=str(file_path),
                content=content,
                content_type=content_type
            )
            file_id = reg["id"]
            
            with open(file_path, "wb") as buffer:
                buffer.write(content)

            logger.info(f"File uploaded: {file_path}, Size: {len(content)} bytes, ID: {file_id}")

            if ext == ".pdf":
                # PDFã¯inputãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¦daemonçµŒç”±ã§OCRãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¸
                # (FastAPIã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ç›´æ¥èµ·å‹•ã™ã‚‹ã¨watchdogã¨ç«¶åˆã™ã‚‹ãŸã‚å§”è­²)
                logger.info(f"Saved {file_path} to input folder. Delegating pipeline processing to antigravity_daemon.")
            elif ext in [".md", ".txt"]:
                # Markdown/Textã¯OCRä¸è¦: ç›´æ¥ 00_æœªåˆ†é¡ ã«é…ç½®ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                from config import KNOWLEDGE_BASE_DIR as _KB, UNCATEGORIZED_FOLDER as _UF
                final_md_dir = Path(_KB) / _UF
                final_md_dir.mkdir(parents=True, exist_ok=True)
                final_md_path = final_md_dir / safe_filename

                import shutil
                shutil.move(str(file_path), str(final_md_path))

                from indexer import index_file
                background_tasks.add_task(index_file, str(final_md_path))
                
            # Google Driveã¸ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¹ã‚¯è¿½åŠ 
            from drive_sync import sync_upload_to_drive
            # ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½“ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ç„¡ã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã®å¢—åˆ†åŒæœŸã‚’ã‚­ãƒƒã‚¯ã™ã‚‹
            # ï¼ˆé‡ã„å ´åˆã¯å€‹åˆ¥ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ã‚’drive_syncã«è¿½åŠ ã™ã‚‹ã®ãŒç†æƒ³çš„ï¼‰
            background_tasks.add_task(sync_upload_to_drive)
                
            results.append({
                "filename": file_path.name,
                "status": "uploaded",
                "path": str(file_path),
                "file_id": file_id,
                "original_name": filename
            })
            
        except Exception as e:
            logger.error(f"Upload error for {filename}: {e}", exc_info=True)
            errors.append({"filename": filename, "error": str(e)})
            
    return {"uploaded": results, "errors": errors, "message": f"{len(results)} files uploaded successfully."}


@app.get("/api/files")
def list_files():
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    files = scan_files()
    return {"files": files, "count": len(files)}


@app.get("/api/files/view/{file_path:path}")
async def view_file(file_path: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–²è¦§ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢ï¼ˆKNOWLEDGE_BASE_DIR ä»¥ä¸‹ã®ã¿è¨±å¯ï¼‰
        target_path = Path(KNOWLEDGE_BASE_DIR) / file_path
        if not target_path.resolve().is_relative_to(Path(KNOWLEDGE_BASE_DIR).resolve()):
            raise HTTPException(status_code=403, detail="Access denied")
           
        if not target_path.exists():
            raise HTTPException(status_code=404, detail="File not found")
            
        # PDFã®å ´åˆã¯ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³è¡¨ç¤ºï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        headers = {}
        if target_path.suffix.lower() == ".pdf":
            media_type = "application/pdf"
            # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ãŠã
            from urllib.parse import quote
            safe_name = quote(target_path.name)
            headers["Content-Disposition"] = f"inline; filename*=utf-8''{safe_name}"
        else:
            media_type = "application/octet-stream"
            
        # filenameãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç›´æ¥æ¸¡ã™ã¨Content-DispositionãŒattachmentã«ãªã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€headersã‚’ä½¿ç”¨
        if headers:
            return FileResponse(target_path, media_type=media_type, headers=headers)
        else:
            return FileResponse(target_path, filename=target_path.name)
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))


# NOTE: GET /api/pdf/{file_id} ã¯ get_pdf() ã«çµ±åˆæ¸ˆã¿ï¼ˆfile_storeãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
# NOTE: GET /api/pdf/metadata/{file_id} ã¯ get_pdf_metadata() ã«çµ±åˆæ¸ˆã¿ï¼ˆpypdfå¯¾å¿œï¼‰

@app.get("/api/pdf/list")
def list_pdfs():
    """ä¿å­˜æ¸ˆã¿PDFã®ä¸€è¦§ã‚’å–å¾—"""
    from database import get_session, Document as DbDocument
    session = get_session()
    try:
        # file_hashãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€è¦§
        docs = session.query(DbDocument).filter(
            DbDocument.file_hash.isnot(None), 
            DbDocument.file_type == "pdf"
        ).all()
        return [{"file_id": d.file_hash, "filename": d.filename} for d in docs]
    finally:
        session.close()




@app.get("/api/system/export-source")
async def export_source():
    """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¸€å¼ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        import zipfile
        from io import BytesIO
        from datetime import datetime
        
        # é™¤å¤–è¨­å®š
        EXCLUDE_DIRS = {
            'node_modules', 'venv', '.git', '__pycache__', 
            'knowledge_base', 'chroma_db', '.next', '.idea', '.vscode',
            'brain', '.gemini', 'artifacts' # Agentic artifacts
        }
        EXCLUDE_FILES = {
            '.DS_Store', 'ocr_progress.json', 'file_index.json', 'credentials.json'
        }
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ä½œæˆ
        zip_buffer = BytesIO()
        base_dir = Path(__file__).parent.resolve()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(base_dir):
                # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤ï¼ˆin-placeå¤‰æ›´ã§ãã®å¾Œã®walkã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
                
                for file in files:
                    if file in EXCLUDE_FILES or file.endswith('.webp') or file.endswith('.png'):
                        continue
                        
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(base_dir)
                    zf.write(file_path, arcname)
                    
        zip_buffer.seek(0)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"antigravity_source_{timestamp}.zip"
        
        # FastAPIã®Responseã ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒé›£ã—ã„å ´åˆãŒã‚ã‚‹ã®ã§ã€
        # uvicornãªã‚‰StreamingResponseã‚’ä½¿ã†ã®ãŒè‰¯ã„ãŒã€
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’é£Ÿã‚ãªã„ã‚ˆã†ã«ãƒ¡ãƒ¢ãƒªã§ä½œã£ã¦ä¸€æ‹¬ã§è¿”ã™ï¼ˆå°è¦æ¨¡ãªã‚‰OKï¼‰
        
        from fastapi.responses import StreamingResponse
        
        return StreamingResponse(
            iter([zip_buffer.getvalue()]), 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
        
    except Exception as e:
        print(f"Export error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


class DeleteFileRequest(BaseModel):
    file_path: str


@app.delete("/api/files/delete")
async def delete_file(request: DeleteFileRequest):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«ï¼‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰"""
    try:
        from config import KNOWLEDGE_BASE_DIR
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
        target_path = Path(KNOWLEDGE_BASE_DIR) / request.file_path
        if not target_path.resolve().is_relative_to(Path(KNOWLEDGE_BASE_DIR).resolve()):
            raise HTTPException(status_code=403, detail="Access denied")
            
        if not target_path.exists():
             raise HTTPException(status_code=404, detail="File not found")
        
        # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤
        from indexer import delete_from_index
        delete_from_index(str(request.file_path))
        
        # 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‹ã‚‰å‰Šé™¤
        from status_manager import OCRStatusManager
        OCRStatusManager().remove_status(str(request.file_path))
        
        # 3. ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        # Markdownãªã‚‰å¯¾ã«ãªã‚‹PDFã‚‚å‰Šé™¤ã€PDFãªã‚‰å¯¾ã«ãªã‚‹Markdownã‚‚å‰Šé™¤
        files_to_delete = [target_path]
        
        if target_path.suffix.lower() == '.md':
            pdf_path = target_path.with_suffix('.pdf')
            if pdf_path.exists():
                files_to_delete.append(pdf_path)
        elif target_path.suffix.lower() == '.pdf':
            md_path = target_path.with_suffix('.md')
            if md_path.exists():
                files_to_delete.append(md_path)
                
        deleted_files = []
        for f in files_to_delete:
            try:
                os.remove(f)
                deleted_files.append(f.name)
            except Exception as e:
                print(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼ ({f.name}): {e}")
                
        return {"success": True, "deleted": deleted_files}
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"Delete file error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

class BulkDeleteRequest(BaseModel):
    file_paths: List[str]

@app.delete("/api/files/bulk-delete")
async def bulk_delete_files(request: BulkDeleteRequest):
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‰Šé™¤"""
    try:
        from config import KNOWLEDGE_BASE_DIR
        from indexer import delete_from_index
        from status_manager import OCRStatusManager
        
        status_mgr = OCRStatusManager()
        deleted_count = 0
        errors = []
        
        for file_path in request.file_paths:
            try:
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
                target_path = Path(KNOWLEDGE_BASE_DIR) / file_path
                if not target_path.resolve().is_relative_to(Path(KNOWLEDGE_BASE_DIR).resolve()):
                    errors.append(f"{file_path}: Access denied")
                    continue
                    
                if not target_path.exists():
                     pass
                else:
                    files_to_delete = [target_path]
                    
                    if target_path.suffix.lower() == '.md':
                        pdf_path = target_path.with_suffix('.pdf')
                        if pdf_path.exists():
                            files_to_delete.append(pdf_path)
                    elif target_path.suffix.lower() == '.pdf':
                        md_path = target_path.with_suffix('.md')
                        if md_path.exists():
                            files_to_delete.append(md_path)
                            
                    for f in files_to_delete:
                        if f.exists():
                            f.unlink()
                
                delete_from_index(str(file_path))
                status_mgr.remove_status(str(file_path))
                deleted_count += 1
                
            except Exception as e:
                print(f"Failed to delete {file_path}: {e}")
                errors.append(f"{file_path}: {str(e)}")
                
        return {
            "status": "success", 
            "message": f"{deleted_count} files processed",
            "errors": errors
        }
    except Exception as e:
        print(f"Bulk delete error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


def build_tree_recursive(current_path: Path, root_path: Path, ocr_progress_data: dict):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ„ãƒªãƒ¼ã‚’å†å¸°çš„ã«æ§‹ç¯‰"""
    rel_path = str(current_path.relative_to(root_path)) if current_path != root_path else ""
    node = {
        "name": current_path.name,
        "type": "directory",
        "path": rel_path,
        "children": []
    }
    
    try:
        if not current_path.exists():
            return node
            
        items = sorted(current_path.iterdir(), key=lambda x: (not x.is_dir(), x.name.lower()))
        for item in items:
            if item.name.startswith('.') or item.name == '__pycache__' or item.name == 'chroma_db':
                continue
                
            if item.is_dir():
                node["children"].append(build_tree_recursive(item, root_path, ocr_progress_data))
            else:
                ext = item.suffix.lower()
                # è¡¨ç¤ºå¯¾è±¡ã®æ‹¡å¼µå­ï¼ˆ.mdã‚‚å«ã‚ã‚‹ï¼‰
                if ext not in SUPPORTED_EXTENSIONS and ext != '.md': 
                    continue
                
                item_rel_path = str(item.relative_to(root_path))
                ocr_status = "none"
                ocr_progress = None
                
                if ext == '.pdf':
                    # ã¾ãš .md ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã§å®Œäº†ç¢ºèªï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•å¾Œã§ã‚‚ç¢ºå®Ÿã«æ¤œå‡ºï¼‰
                    md_path = item.with_suffix('.md')
                    if md_path.exists():
                        ocr_status = "completed"
                    
                    # Status Managerã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã§ä¸Šæ›¸ãï¼ˆprocessing/failedå„ªå…ˆï¼‰
                    if item_rel_path in ocr_progress_data:
                        progress_info = ocr_progress_data[item_rel_path]
                        status = progress_info.get("status")
                        if status == "processing":
                            ocr_status = "processing"
                            ocr_progress = {
                                "current": progress_info.get("processed_pages", 0),
                                "total": progress_info.get("total_pages", 1),
                                "estimated_remaining": progress_info.get("estimated_remaining")
                            }
                        elif status == "failed":
                            ocr_status = "failed"
                            ocr_progress = {"error": progress_info.get("error")}

                node["children"].append({
                    "name": item.name,
                    "type": "file",
                    "path": item_rel_path,
                    "size": item.stat().st_size,
                    "ocr_status": ocr_status,
                    "ocr_progress": ocr_progress
                })
    except Exception as e:
        print(f"Tree build error: {e}")
        
    return node


@app.get("/api/files/tree")
def get_files_tree():
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ„ãƒªãƒ¼ã‚’å–å¾—"""
    from status_manager import OCRStatusManager
    status_mgr = OCRStatusManager()
    progress_data = status_mgr.get_all_status()
    
    return build_tree_recursive(Path(KNOWLEDGE_BASE_DIR), Path(KNOWLEDGE_BASE_DIR), progress_data)


@app.get("/api/categories")
async def list_categories():
    """åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒªä¸€è¦§"""
    categories = [
        {"value": None, "label": "å…¨ã¦ï¼ˆæ¨ªæ–­æ¤œç´¢ï¼‰"},
        {"value": "01_ã‚«ã‚¿ãƒ­ã‚°", "label": "01 ã‚«ã‚¿ãƒ­ã‚°"},
        {"value": "02_å›³é¢", "label": "02 å›³é¢"},
        {"value": "03_æŠ€è¡“åŸºæº–", "label": "03 æŠ€è¡“åŸºæº–"},
        {"value": "04_ãƒªã‚µãƒ¼ãƒæˆæœç‰©", "label": "04 ãƒªã‚µãƒ¼ãƒæˆæœç‰©"},
        {"value": "05_æ³•è¦", "label": "05 æ³•è¦"},
        {"value": "06_è¨­è¨ˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ", "label": "06 è¨­è¨ˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ"},
        {"value": "07_ã‚³ã‚¹ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ", "label": "07 ã‚³ã‚¹ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ"},
        {"value": "00_æœªåˆ†é¡", "label": "00 æœªåˆ†é¡"},
    ]
    return {"categories": categories}


# ========== Google Drive é€£æº ==========

@app.get("/api/drive/status")
def drive_status():
    """Google Driveèªè¨¼çŠ¶æ…‹ã‚’ç¢ºèª"""
    try:
        from drive_sync import get_auth_status
        return get_auth_status()
    except ImportError:
        return {"authenticated": False, "message": "drive_sync ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"}
    except Exception as e:
        return {"authenticated": False, "message": str(e)}


@app.post("/api/drive/auth")
def drive_auth(request: Request):
    """Google Driveèªè¨¼URLã‚’å–å¾—"""
    try:
        from drive_sync import get_auth_url
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰URLã®ãƒ™ãƒ¼ã‚¹éƒ¨åˆ†ã‚’å–å¾— (ä¾‹: https://antigravity.rag-architecture.com)
        # Nginx/Cloudflareãƒ—ãƒ­ã‚­ã‚·ç­‰ã‚’çµŒç”±ã—ã¦ã„ã‚‹å ´åˆã¯ Forwardedãƒ˜ãƒƒãƒ€ ã‚„ origin ã‚’å„ªå…ˆä½¿ç”¨
        origin = request.headers.get("origin")
        if not origin:
            scheme = request.headers.get("x-forwarded-proto", request.url.scheme)
            host = request.headers.get("x-forwarded-host", request.url.netloc)
            origin = f"{scheme}://{host}"
            
        redirect_uri = f"{origin}/api/drive/callback"
        
        url = get_auth_url(redirect_uri=redirect_uri)
        return {"success": True, "auth_url": url}
    except FileNotFoundError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        import traceback
        traceback.print_exc()  # ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°ã«å‡ºåŠ›
        raise HTTPException(status_code=500, detail=f"{str(e)}\n{traceback.format_exc()}")


@app.get("/api/drive/callback")
def drive_callback(request: Request, code: str):
    """Googleã‹ã‚‰ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’å—ã‘å–ã‚Šèªè¨¼å®Œäº†"""
    try:
        from drive_sync import save_credentials_from_code
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰URLã®ãƒ™ãƒ¼ã‚¹éƒ¨åˆ†ã‚’å–å¾—
        scheme = request.headers.get("x-forwarded-proto", request.url.scheme)
        host = request.headers.get("x-forwarded-host", request.url.netloc)
        origin = f"{scheme}://{host}"
        
        redirect_uri = f"{origin}/api/drive/callback"
        save_credentials_from_code(code, redirect_uri=redirect_uri)
        
        # å®Œäº†å¾Œã«ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¸ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
        return RedirectResponse(url=f"{origin}/?auth=success")
    except Exception as e:
        return {"error": str(e)}


@app.post("/api/drive/upload")
async def drive_upload(background_tasks: BackgroundTasks):
    """Google Driveã¸ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    try:
        from drive_sync import backup_to_drive
        background_tasks.add_task(backup_to_drive)
        return {"status": "success", "message": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class DriveSyncRequest(BaseModel):
    folder_name: str = "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB"


@app.post("/api/drive/sync")
async def drive_sync(request: DriveSyncRequest):
    """Google Driveãƒ•ã‚©ãƒ«ãƒ€ã‚’åŒæœŸ"""
    try:
        from drive_sync import find_folder_by_name, sync_drive_folder
        
        # ãƒ•ã‚©ãƒ«ãƒ€IDã‚’æ¤œç´¢
        folder_id = find_folder_by_name(request.folder_name)
        if not folder_id:
            raise HTTPException(
                status_code=404,
                detail=f"ãƒ•ã‚©ãƒ«ãƒ€ '{request.folder_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
        
        # åŒæœŸå®Ÿè¡Œ
        stats = sync_drive_folder(folder_id, request.folder_name)
        return {
            "success": True,
            "folder_name": request.folder_name,
            **stats
        }
    except ImportError:
        raise HTTPException(status_code=500, detail="drive_sync ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/drive/folders")
async def drive_list_folders(parent_id: str = "root"):
    """Google Driveã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’å–å¾—"""
    try:
        from drive_sync import get_drive_service, list_drive_folders
        service = get_drive_service()
        folders = list_drive_folders(service, parent_id)
        return {"folders": folders}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



@app.post("/api/sync-drive")
async def sync_to_drive():
    """ãƒ­ãƒ¼ã‚«ãƒ«ã®æ•´ç†æ¸ˆã¿ãƒ•ã‚©ãƒ«ãƒ€ã‚’Google Driveã«åŒæœŸï¼ˆLocal -> Drive Mirror Uploadï¼‰"""
    try:
        # ãƒ•ã‚©ãƒ«ãƒ€åã¯ 'å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB' å›ºå®šã€ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        folder_name = "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB"
        
        # ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾— (å­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ)
        from drive_sync import find_folder_by_name, create_folder, get_drive_service
        from config import KNOWLEDGE_BASE_DIR
        
        service = get_drive_service()
        folder_id = find_folder_by_name(folder_name)
        if not folder_id:
            folder_id = create_folder(service, folder_name)
            
        # åŒæœŸå®Ÿè¡Œ (KNOWLEDGE_BASE_DIR ä»¥ä¸‹ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡)
        from drive_sync import upload_mirror_to_drive
        result = upload_mirror_to_drive(str(KNOWLEDGE_BASE_DIR), folder_id)
        
        return result
    except ImportError:
        raise HTTPException(status_code=500, detail="drive_sync module not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/upload")
async def upload_file(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    """
    Webç”»é¢ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã€file_storeã«ç™»éŒ²ã™ã‚‹ã€‚
    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£:
    - è¨±å¯ã•ã‚ŒãŸæ‹¡å¼µå­ã®ã¿å—ä»˜
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™ 100MB
    - ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚º
    """
    ALLOWED_EXTENSIONS = {".pdf", ".png", ".jpg", ".jpeg"}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    
    filename = file.filename or "unknown"
    filename = os.path.basename(filename)
    ext = os.path.splitext(filename)[1].lower()
    
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"Unsupported file type: {ext}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚º
    # werkzeug ã® secure_filename() ã¯æ—¥æœ¬èªã‚’é™¤å»ã—ã¦ã—ã¾ã†ãŸã‚ä½¿ã‚ãªã„
    import re
    safe_filename = re.sub(r'[/\\:*?"<>|]', '_', filename).strip()
    if not safe_filename or safe_filename == ext or safe_filename.lstrip('.') == '':
        safe_filename = f"file_{int(time.time())}{ext}"
    if not safe_filename.lower().endswith(ext):
        safe_filename = safe_filename + ext
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ç¢ºä¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ã¦Google Drive evictionã‚’å›é¿ï¼‰
    from config import KNOWLEDGE_BASE_DIR, BASE_DIR
    input_dir = Path(BASE_DIR) / "input"
    input_dir.mkdir(parents=True, exist_ok=True)
    
    base_name = Path(safe_filename).stem
    file_path = input_dir / safe_filename
    timestamp = int(time.time())
    if file_path.exists():
        file_path = input_dir / f"{base_name}_{timestamp}{ext}"
    
    try:
        content = await file.read()
        
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413, 
                detail=f"File too large. Maximum size is {MAX_FILE_SIZE // (1024*1024)}MB"
            )
        
        # file_storeã«ç™»éŒ² (è«–ç†ID = SHA-256å…ˆé ­16æ–‡å­—)
        import file_store
        content_type = "application/pdf" if ext == ".pdf" else f"image/{ext[1:]}"
        reg = file_store.register_file(
            original_name=filename,
            current_path=str(file_path),
            content=content,
            content_type=content_type
        )
        file_id = reg["id"]
        
        # inputãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼ˆOCR/åˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ï¼‰
        # é‡è¤‡ä¿å­˜ã¯åœæ­¢: PDF_STORAGE_DIR ã¸ã® {file_id}.pdf ã‚³ãƒ”ãƒ¼ã¯å»ƒæ­¢
        with open(file_path, "wb") as buffer:
            buffer.write(content)
        logger.info(f"File uploaded: {file_path}, Size: {len(content)} bytes, ID: {file_id}")
        
        # è‡ªå‹•å‡¦ç†é–‹å§‹ (PDFã®ã¿)
        if ext == ".pdf":
            from pipeline_manager import process_file_pipeline
            background_tasks.add_task(process_file_pipeline, str(file_path))
        elif ext in [".md", ".txt"]:
            from indexer import index_file
            # Markdown/Textãƒ•ã‚¡ã‚¤ãƒ«ã¯OCRä¸è¦ãªãŸã‚ã€ç›´æ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆChunkingï¼‰ã«è¿½åŠ ã™ã‚‹
            background_tasks.add_task(index_file, str(file_path))

        # Google Driveã¸ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¹ã‚¯è¿½åŠ 
        from drive_sync import sync_upload_to_drive
        background_tasks.add_task(sync_upload_to_drive)

        return {
            "filename": file_path.name, 
            "status": "uploaded", 
            "path": str(file_path),
            "file_id": file_id,
            "original_name": filename,
            "message": "File uploaded successfully. Automatic classification will start shortly."
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Upload error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ========== PDF Delivery & File Info API ==========

@app.get("/api/pdf/{file_id}")
async def get_pdf(file_id: str):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªé…ä¿¡ï¼ˆfile_storeã‹ã‚‰è§£æ±ºã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Šï¼‰"""
    if not file_id.isalnum():
        raise HTTPException(status_code=400, detail="Invalid file_id")
    
    # 1. file_storeã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    try:
        import file_store
        file_info = file_store.get_file(file_id)
        if file_info:
            fp = Path(file_info["current_path"])
            if fp.exists():
                return FileResponse(fp, media_type="application/pdf",
                                   filename=file_info.get("original_name", fp.name))
    except Exception:
        pass
    
    # 2. PDF_STORAGE_DIRå†…ã®IDåãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from config import PDF_STORAGE_DIR
    target_path = Path(PDF_STORAGE_DIR) / f"{file_id}.pdf"
    if target_path.exists():
        return FileResponse(target_path, media_type="application/pdf")
    
    raise HTTPException(status_code=404, detail="PDF not found")


@app.get("/api/files/{file_id}/info")
def get_file_info(file_id: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ãƒ‘ã‚¹ã€åŒæœŸçŠ¶æ…‹ç­‰ï¼‰"""
    try:
        import file_store
        info = file_store.get_file(file_id)
        if not info:
            raise HTTPException(status_code=404, detail="File not found")
        return info
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tags")
def get_tags():
    """åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚°ä¸€è¦§ã‚’å–å¾—"""
    try:
        import yaml
        base_dir = Path(".")
        rules_path = base_dir / "classification_rules.yaml"
        if not rules_path.exists():
            return {}
            
        with open(rules_path, 'r', encoding='utf-8') as f:
            rules = yaml.safe_load(f)
            
        return rules.get("available_tags", {})
    except Exception as e:
        logger.error(f"Failed to load tags: {e}")
        return {}

@app.get("/api/pdf/metadata/{file_id}")
async def get_pdf_metadata(file_id: str):
    """PDFãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    import pypdf
    from config import PDF_STORAGE_DIR
    
    if not file_id.isalnum():
         raise HTTPException(status_code=400, detail="Invalid file_id")

    target_path = Path(PDF_STORAGE_DIR) / f"{file_id}.pdf"
    
    if not target_path.exists():
        raise HTTPException(status_code=404, detail="PDF not found")
        
    try:
        reader = pypdf.PdfReader(target_path)
        return {
            "file_id": file_id,
            "page_count": len(reader.pages),
            "size_bytes": target_path.stat().st_size
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



# ========== è¨­å®šé–¢é€£ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==========

class GeminiKeyRequest(BaseModel):
    api_key: str

@app.get("/api/settings/gemini-key")
async def get_gemini_key():
    """è¨­å®šæ¸ˆã¿ã®Gemini APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ä¸€éƒ¨éš è”½ï¼‰"""
    api_key = os.environ.get("GEMINI_API_KEY", "")
    if not api_key:
        return {"api_key": "", "configured": False}
    
    # å‰å¾Œæ•°æ–‡å­—ã ã‘è¡¨ç¤º
    if len(api_key) > 8:
        masked = f"{api_key[:4]}...{api_key[-4:]}"
    else:
        masked = "****"
        
    return {"api_key": masked, "configured": True}

@app.post("/api/settings/gemini-key")
async def set_gemini_key(request: GeminiKeyRequest):
    """Gemini APIã‚­ãƒ¼ã‚’è¨­å®šãƒ»ä¿å­˜"""
    new_key = request.api_key.strip()
    if not new_key:
        raise HTTPException(status_code=400, detail="APIã‚­ãƒ¼ãŒç©ºã§ã™")
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    env_path = Path(".env")
    lines = []
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
    key_exists = False
    new_lines = []
    for line in lines:
        if line.strip().startswith("GEMINI_API_KEY="):
            new_lines.append(f"GEMINI_API_KEY={new_key}\n")
            key_exists = True
        else:
            new_lines.append(line)
            
    if not key_exists:
        if new_lines and not new_lines[-1].endswith('\n'):
            new_lines[-1] += '\n'
        new_lines.append(f"GEMINI_API_KEY={new_key}\n")
        
    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)
        
    # ç’°å¢ƒå¤‰æ•°ã¨configã‚’æ›´æ–°
    os.environ["GEMINI_API_KEY"] = new_key
    import config
    config.GEMINI_API_KEY = new_key
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å†ç”Ÿæˆ
    import gemini_client as _gc
    _gc.reconfigure(new_key)

    return {"message": "APIã‚­ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ"}

@app.post("/api/settings/test-gemini")
async def test_gemini_key():
    """ç¾åœ¨ã®APIã‚­ãƒ¼ã§Geminiæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    import config

    if not config.GEMINI_API_KEY:
        raise HTTPException(status_code=400, detail="APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
    try:
        from google.genai import types as _types
        from gemini_client import get_client as _get_client
        _client = _get_client()
        _response = _client.models.generate_content(
            model="gemini-2.0-flash",
            contents="Hello, this is a connection test.",
        )
        return {"success": True, "message": "æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ", "response": _response.text[:50]}
    except Exception as e:
        return {"success": False, "message": f"æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

