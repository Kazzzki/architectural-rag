import patch_importlib  # æœ€å„ªå…ˆã§å®Ÿè¡Œ
import os
import sys
# ä»¥å‰ã®ãƒ‘ãƒƒãƒã¯ patch_importlib.py ã«ç§»å‹•ã—ãŸã®ã§å‰Šé™¤
# (é‡è¤‡ã—ã¦ã‚‚å•é¡Œãªã„ãŒã‚­ãƒ¬ã‚¤ã«ã™ã‚‹)

import shutil
import time
from pathlib import Path
from typing import Optional, List
from datetime import datetime
import logging

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, RedirectResponse, FileResponse, JSONResponse
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from pydantic import BaseModel
import secrets
# Logging setup (Phase 3)
logging.basicConfig(
    filename='app.log',
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    encoding='utf-8'
)
# Console handler
console = logging.StreamHandler()
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

logger = logging.getLogger(__name__)

from config import (
    CORS_ORIGINS,
    KNOWLEDGE_BASE_DIR,
    SUPPORTED_EXTENSIONS,
    GEMINI_API_KEY,
)
from retriever import search, build_context, get_source_files, get_db_stats
from generator import generate_answer, generate_answer_stream
from ocr_processor import process_pdf_background
from indexer import build_index, scan_files

# Gemini APIè¨­å®š
import google.generativeai as genai
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Basicèªè¨¼è¨­å®šï¼ˆãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã§å…¨APIä¿è­·ï¼‰
APP_PASSWORD = os.environ.get("APP_PASSWORD", "")

if APP_PASSWORD:
    import base64
    from starlette.middleware.base import BaseHTTPMiddleware
    from starlette.responses import Response

    class BasicAuthMiddleware(BaseHTTPMiddleware):
        """APP_PASSWORDè¨­å®šæ™‚ã«å…¨APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’Basicèªè¨¼ã§ä¿è­·"""
        # èªè¨¼ä¸è¦ã®ãƒ‘ã‚¹
        EXEMPT_PATHS = {"/api/health", "/docs", "/openapi.json"}

        async def dispatch(self, request, call_next):
            path = request.url.path

            # èªè¨¼ä¸è¦ãƒ‘ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
            if path in self.EXEMPT_PATHS:
                return await call_next(request)

            # OPTIONSãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆCORSãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
            if request.method == "OPTIONS":
                return await call_next(request)

            # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»éAPIãƒ‘ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
            if not path.startswith("/api/"):
                return await call_next(request)

            # Authorization ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œè¨¼
            auth = request.headers.get("Authorization")
            if auth and auth.startswith("Basic "):
                try:
                    decoded = base64.b64decode(auth[6:]).decode("utf-8")
                    _, password = decoded.split(":", 1)
                    if secrets.compare_digest(password, APP_PASSWORD):
                        return await call_next(request)
                except Exception:
                    pass

            return Response(
                content="èªè¨¼ãŒå¿…è¦ã§ã™",
                status_code=401,
                headers={"WWW-Authenticate": 'Basic realm="Antigravity RAG"'},
            )

    print("ğŸ”’ Basicèªè¨¼ãŒæœ‰åŠ¹ã§ã™ (APP_PASSWORDè¨­å®šæ¸ˆ)")
else:
    print("âš ï¸  APP_PASSWORDãŒæœªè¨­å®šã®ãŸã‚ã€èªè¨¼ãªã—ã§å‹•ä½œã—ã¾ã™")


app = FastAPI(
    title="å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸RAG API",
    description="å»ºç¯‰PM/CMæ¥­å‹™å‘ã‘ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ãƒ»å›ç­”ç”ŸæˆAPI",
    version="1.0.0",
)

# èªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’ç™»éŒ²
if APP_PASSWORD:
    app.add_middleware(BasicAuthMiddleware)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
from database import init_db, migrate_from_json
init_db()
# åˆå›èµ·å‹•æ™‚ã«æ—¢å­˜JSONãƒ‡ãƒ¼ã‚¿ã‚’DBã¸ç§»è¡Œ
try:
    migrate_from_json()
except Exception as e:
    print(f"JSON migration skipped or error: {e}")

# ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ãƒã‚¦ãƒ³ãƒˆ
from mindmap.router import router as mindmap_router
app.include_router(mindmap_router)

# Global Exception Handler (Phase 3)
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    import traceback
    error_detail = {
        "error": str(exc),
        "type": type(exc).__name__,
        "path": request.url.path
    }
    if os.environ.get("DEBUG", "false").lower() == "true":
        error_detail["traceback"] = traceback.format_exc()
    
    logger.error(f"Global Error: {exc} at {request.url.path}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content=error_detail
    )

# CORSè¨­å®š (ngrokå¯¾å¿œ)
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,  # config.pyã§å®šç¾©ã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒ³
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class ChatRequest(BaseModel):
    question: str
    category: Optional[str] = None
    file_type: Optional[str] = None
    date_range: Optional[str] = None
    tags: Optional[List[str]] = None
    tag_match_mode: Optional[str] = "any"


class ChatResponse(BaseModel):
    answer: str
    sources: List[dict]


class StatsResponse(BaseModel):
    file_count: int
    chunk_count: int
    last_updated: str


class IndexResponse(BaseModel):
    total_files: int
    indexed: int
    skipped: int
    errors: int
    chunks: int


class FileInfo(BaseModel):
    filename: str
    category: str
    size_kb: float
    uploaded_at: str


# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    return {"message": "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸RAG API", "status": "running"}


@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆ"""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    try:
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        search_results = search(
            request.question, 
            filter_category=request.category,
            filter_file_type=request.file_type,
            filter_date_range=request.date_range
        )
        
        logger.info(f"Query: {request.question}, Results: {len(search_results['ids'][0]) if search_results['ids'] else 0}")

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context = build_context(search_results)
        
        # ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        source_files = get_source_files(search_results)
        
        # å›ç­”ç”Ÿæˆ
        answer = generate_answer(request.question, context, source_files)
        
        logger.info(f"Answer generated ({len(answer)} chars)")
        
        return ChatResponse(answer=answer, sources=source_files)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å½¢å¼ã§å›ç­”ã‚’ç”Ÿæˆ (Phase 2: SSEå¯¾å¿œ)"""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    try:
        search_results = search(
            request.question, 
            filter_category=request.category,
            filter_file_type=request.file_type,
            filter_date_range=request.date_range
        )
        context = build_context(search_results)
        source_files = get_source_files(search_results)
        
        async def generate():
            import json
            # 1. ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å…ˆã«é€ä¿¡
            yield f"data: {json.dumps({'type': 'sources', 'data': source_files}, ensure_ascii=False)}\n\n"
            
            # 2. å›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            async for chunk in generate_answer_stream(request.question, context, source_files):
                # chunkã¯ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ã¨ä»®å®š
                yield f"data: {json.dumps({'type': 'answer', 'data': chunk}, ensure_ascii=False)}\n\n"
            
            # 3. å®Œäº†ã‚·ã‚°ãƒŠãƒ«
            yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            generate(), 
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            }
        )
        
    except Exception as e:
        print(f"Stream Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/stats", response_model=StatsResponse)
async def get_stats():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆã‚’å–å¾—"""
    stats = get_db_stats()
    return StatsResponse(
        file_count=stats["file_count"],
        chunk_count=stats["chunk_count"],
        last_updated=stats["last_updated"] or "æœªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
    )


@app.post("/api/index", response_model=IndexResponse)
async def rebuild_index(force: bool = False):
    """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰"""
    try:
        stats = build_index(force_rebuild=force)
        return IndexResponse(**stats)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# Old upload_file implementation removed to avoid duplicate endpoint


@app.post("/api/upload/multiple")
async def upload_multiple_files(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    category: str = "uploads"
):
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    results = []
    errors = []
    
    for file in files:
        ext = Path(file.filename).suffix.lower()
        if ext not in SUPPORTED_EXTENSIONS:
            errors.append({"filename": file.filename, "error": f"æœªå¯¾å¿œå½¢å¼: {ext}"})
            continue
        
        try:
            save_dir = Path(KNOWLEDGE_BASE_DIR) / category
            save_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = save_dir / file.filename
            with open(file_path, "wb") as f:
                shutil.copyfileobj(file.file, f)
            
            # PDFãªã‚‰è‡ªå‹•åˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
            if ext == '.pdf':
                from pipeline_manager import process_file_pipeline
                background_tasks.add_task(process_file_pipeline, str(file_path))

            results.append({
                "filename": file.filename,
                "category": category,
                "size_kb": round(file_path.stat().st_size / 1024, 2),
            })
        except Exception as e:
            errors.append({"filename": file.filename, "error": str(e)})
    
    return {"uploaded": results, "errors": errors}


@app.get("/api/files")
async def list_files():
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    files = scan_files()
    return {"files": files, "count": len(files)}


@app.get("/api/files/view/{file_path:path}")
async def view_file(file_path: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–²è¦§ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
        target_path = Path(KNOWLEDGE_BASE_DIR) / file_path
        if not target_path.resolve().is_relative_to(Path(KNOWLEDGE_BASE_DIR).resolve()):
            raise HTTPException(status_code=403, detail="Access denied")
           
        if not target_path.exists():
            raise HTTPException(status_code=404, detail="File not found")
            
        return FileResponse(target_path, filename=target_path.name)
    except Exception as e:
        raise HTTPException(status_code=404, detail=str(e))


@app.get("/api/system/export-source")
async def export_source():
    """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¸€å¼ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        import zipfile
        from io import BytesIO
        from datetime import datetime
        
        # é™¤å¤–è¨­å®š
        EXCLUDE_DIRS = {
            'node_modules', 'venv', '.git', '__pycache__', 
            'knowledge_base', 'chroma_db', '.next', '.idea', '.vscode',
            'brain', '.gemini', 'artifacts' # Agentic artifacts
        }
        EXCLUDE_FILES = {
            '.DS_Store', 'ocr_progress.json', 'file_index.json', 'credentials.json'
        }
        
        # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ä½œæˆ
        zip_buffer = BytesIO()
        base_dir = Path(__file__).parent.resolve()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            for root, dirs, files in os.walk(base_dir):
                # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤ï¼ˆin-placeå¤‰æ›´ã§ãã®å¾Œã®walkã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
                
                for file in files:
                    if file in EXCLUDE_FILES or file.endswith('.webp') or file.endswith('.png'):
                        continue
                        
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(base_dir)
                    zf.write(file_path, arcname)
                    
        zip_buffer.seek(0)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"antigravity_source_{timestamp}.zip"
        
        # FastAPIã®Responseã ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãŒé›£ã—ã„å ´åˆãŒã‚ã‚‹ã®ã§ã€
        # uvicornãªã‚‰StreamingResponseã‚’ä½¿ã†ã®ãŒè‰¯ã„ãŒã€
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’é£Ÿã‚ãªã„ã‚ˆã†ã«ãƒ¡ãƒ¢ãƒªã§ä½œã£ã¦ä¸€æ‹¬ã§è¿”ã™ï¼ˆå°è¦æ¨¡ãªã‚‰OKï¼‰
        
        from fastapi.responses import StreamingResponse
        
        return StreamingResponse(
            iter([zip_buffer.getvalue()]), 
            media_type="application/zip",
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
        
    except Exception as e:
        print(f"Export error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


class DeleteFileRequest(BaseModel):
    file_path: str


@app.delete("/api/files/delete")
async def delete_file(request: DeleteFileRequest):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«ï¼‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰"""
    try:
        from config import KNOWLEDGE_BASE_DIR
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
        target_path = Path(KNOWLEDGE_BASE_DIR) / request.file_path
        if not target_path.resolve().is_relative_to(Path(KNOWLEDGE_BASE_DIR).resolve()):
            raise HTTPException(status_code=403, detail="Access denied")
            
        if not target_path.exists():
             raise HTTPException(status_code=404, detail="File not found")
        
        # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤
        from indexer import delete_from_index
        delete_from_index(str(request.file_path))
        
        # 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‹ã‚‰å‰Šé™¤
        from status_manager import OCRStatusManager
        OCRStatusManager().remove_status(str(request.file_path))
        
        # 3. ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        # Markdownãªã‚‰å¯¾ã«ãªã‚‹PDFã‚‚å‰Šé™¤ã€PDFãªã‚‰å¯¾ã«ãªã‚‹Markdownã‚‚å‰Šé™¤
        files_to_delete = [target_path]
        
        if target_path.suffix.lower() == '.md':
            pdf_path = target_path.with_suffix('.pdf')
            if pdf_path.exists():
                files_to_delete.append(pdf_path)
        elif target_path.suffix.lower() == '.pdf':
            md_path = target_path.with_suffix('.md')
            if md_path.exists():
                files_to_delete.append(md_path)
                
        deleted_files = []
        for f in files_to_delete:
            try:
                os.remove(f)
                deleted_files.append(f.name)
            except Exception as e:
                print(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼ ({f.name}): {e}")
                
        return {"success": True, "deleted": deleted_files}
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def build_tree_recursive(current_path: Path, root_path: Path, ocr_progress_data: dict):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ„ãƒªãƒ¼ã‚’å†å¸°çš„ã«æ§‹ç¯‰"""
    rel_path = str(current_path.relative_to(root_path)) if current_path != root_path else ""
    node = {
        "name": current_path.name,
        "type": "directory",
        "path": rel_path,
        "children": []
    }
    
    try:
        if not current_path.exists():
            return node
            
        items = sorted(current_path.iterdir(), key=lambda x: (not x.is_dir(), x.name.lower()))
        for item in items:
            if item.name.startswith('.') or item.name == '__pycache__' or item.name == 'chroma_db':
                continue
                
            if item.is_dir():
                node["children"].append(build_tree_recursive(item, root_path, ocr_progress_data))
            else:
                ext = item.suffix.lower()
                # è¡¨ç¤ºå¯¾è±¡ã®æ‹¡å¼µå­ï¼ˆ.mdã‚‚å«ã‚ã‚‹ï¼‰
                if ext not in SUPPORTED_EXTENSIONS and ext != '.md': 
                    continue
                
                item_rel_path = str(item.relative_to(root_path))
                ocr_status = "none"
                ocr_progress = None
                
                if ext == '.pdf':
                    # Status Managerã‹ã‚‰æƒ…å ±ã‚’å–å¾—
                    if item_rel_path in ocr_progress_data:
                        progress_info = ocr_progress_data[item_rel_path]
                        status = progress_info.get("status")
                        # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å„ªå…ˆ
                        if status == "processing":
                            ocr_status = "processing"
                            ocr_progress = {
                                "current": progress_info.get("processed_pages", 0),
                                "total": progress_info.get("total_pages", 1),
                                "estimated_remaining": progress_info.get("estimated_remaining")
                            }
                        elif status == "completed":
                            ocr_status = "completed"
                        elif status == "failed":
                            ocr_status = "failed"
                            ocr_progress = {"error": progress_info.get("error")}
                    
                    # JSONã«æƒ…å ±ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                    if ocr_status == "none":
                         md_path = item.with_suffix('.md')
                         if md_path.exists():
                             ocr_status = "completed"

                node["children"].append({
                    "name": item.name,
                    "type": "file",
                    "path": item_rel_path,
                    "size": item.stat().st_size,
                    "ocr_status": ocr_status,
                    "ocr_progress": ocr_progress
                })
    except Exception as e:
        print(f"Tree build error: {e}")
        
    return node


@app.get("/api/files/tree")
async def get_files_tree():
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ„ãƒªãƒ¼ã‚’å–å¾—"""
    from status_manager import OCRStatusManager
    status_mgr = OCRStatusManager()
    progress_data = status_mgr.get_all_status()
    
    return build_tree_recursive(Path(KNOWLEDGE_BASE_DIR), Path(KNOWLEDGE_BASE_DIR), progress_data)


@app.get("/api/categories")
async def list_categories():
    """åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒªä¸€è¦§"""
    categories = [
        {"value": None, "label": "å…¨ã¦ï¼ˆæ¨ªæ–­æ¤œç´¢ï¼‰"},
        {"value": "01_ã‚«ã‚¿ãƒ­ã‚°", "label": "01_ã‚«ã‚¿ãƒ­ã‚°"},
        {"value": "02_å›³é¢", "label": "02_å›³é¢"},
        {"value": "03_æŠ€è¡“åŸºæº–", "label": "03_æŠ€è¡“åŸºæº–"},
        {"value": "04_ãƒªã‚µãƒ¼ãƒæˆæœç‰©", "label": "04_ãƒªã‚µãƒ¼ãƒæˆæœç‰©"},
        {"value": "uploads", "label": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"},
    ]
    return {"categories": categories}


# ========== Google Drive é€£æº ==========

@app.get("/api/drive/status")
async def drive_status():
    """Google Driveèªè¨¼çŠ¶æ…‹ã‚’ç¢ºèª"""
    try:
        from drive_sync import get_auth_status
        return get_auth_status()
    except ImportError:
        return {"authenticated": False, "message": "drive_sync ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"}
    except Exception as e:
        return {"authenticated": False, "message": str(e)}


@app.post("/api/drive/auth")
async def drive_auth():
    """Google Driveèªè¨¼URLã‚’å–å¾—"""
    try:
        from drive_sync import get_auth_url
        url = get_auth_url()
        return {"success": True, "auth_url": url}
    except FileNotFoundError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        import traceback
        traceback.print_exc()  # ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°ã«å‡ºåŠ›
        raise HTTPException(status_code=500, detail=f"{str(e)}\n{traceback.format_exc()}")


@app.get("/api/drive/callback")
async def drive_callback(code: str):
    """Googleã‹ã‚‰ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’å—ã‘å–ã‚Šèªè¨¼å®Œäº†"""
    try:
        from drive_sync import save_credentials_from_code
        save_credentials_from_code(code)
        # å®Œäº†å¾Œã«ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¸ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
        return RedirectResponse(url="http://localhost:3000/?auth=success")
    except Exception as e:
        return {"error": str(e)}


@app.post("/api/drive/upload")
async def drive_upload(background_tasks: BackgroundTasks):
    """Google Driveã¸ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    try:
        from drive_sync import backup_to_drive
        background_tasks.add_task(backup_to_drive)
        return {"status": "success", "message": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã—ãŸ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class DriveSyncRequest(BaseModel):
    folder_name: str = "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB"


@app.post("/api/drive/sync")
async def drive_sync(request: DriveSyncRequest):
    """Google Driveãƒ•ã‚©ãƒ«ãƒ€ã‚’åŒæœŸ"""
    try:
        from drive_sync import find_folder_by_name, sync_drive_folder
        
        # ãƒ•ã‚©ãƒ«ãƒ€IDã‚’æ¤œç´¢
        folder_id = find_folder_by_name(request.folder_name)
        if not folder_id:
            raise HTTPException(
                status_code=404,
                detail=f"ãƒ•ã‚©ãƒ«ãƒ€ '{request.folder_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            )
        
        # åŒæœŸå®Ÿè¡Œ
        stats = sync_drive_folder(folder_id, request.folder_name)
        return {
            "success": True,
            "folder_name": request.folder_name,
            **stats
        }
    except ImportError:
        raise HTTPException(status_code=500, detail="drive_sync ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/drive/folders")
async def drive_list_folders(parent_id: str = "root"):
    """Google Driveã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ã‚’å–å¾—"""
    try:
        from drive_sync import get_drive_service, list_drive_folders
        service = get_drive_service()
        folders = list_drive_folders(service, parent_id)
        return {"folders": folders}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



@app.post("/api/sync-drive")
async def sync_to_drive():
    """ãƒ­ãƒ¼ã‚«ãƒ«ã®æ•´ç†æ¸ˆã¿ãƒ•ã‚©ãƒ«ãƒ€ã‚’Google Driveã«åŒæœŸï¼ˆLocal -> Drive Mirror Uploadï¼‰"""
    try:
        # ãƒ•ã‚©ãƒ«ãƒ€åã¯ 'å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB' å›ºå®šã€ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        folder_name = "å»ºç¯‰æ„åŒ ãƒŠãƒ¬ãƒƒã‚¸DB"
        
        # ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾— (å­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ)
        from drive_sync import find_folder_by_name, create_folder, get_drive_service
        
        service = get_drive_service()
        folder_id = find_folder_by_name(folder_name)
        if not folder_id:
            folder_id = create_folder(service, folder_name)
            
        # åŒæœŸå®Ÿè¡Œ (data/ ä»¥ä¸‹ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡)
        from drive_sync import upload_mirror_to_drive
        result = upload_mirror_to_drive("data", folder_id)
        
        return result
    except ImportError:
        raise HTTPException(status_code=500, detail="drive_sync module not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/upload")
async def upload_file(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    """
    Webç”»é¢ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã€file_storeã«ç™»éŒ²ã™ã‚‹ã€‚
    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£:
    - è¨±å¯ã•ã‚ŒãŸæ‹¡å¼µå­ã®ã¿å—ä»˜
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™ 100MB
    - ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚º
    """
    ALLOWED_EXTENSIONS = {".pdf", ".png", ".jpg", ".jpeg"}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    
    filename = file.filename or "unknown"
    filename = os.path.basename(filename)
    ext = os.path.splitext(filename)[1].lower()
    
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"Unsupported file type: {ext}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚µãƒ‹ã‚¿ã‚¤ã‚º
    try:
        from werkzeug.utils import secure_filename
        safe_filename = secure_filename(filename)
    except ImportError:
        import re
        safe_filename = re.sub(r'[^\w\-_\. ]', '_', filename)
    
    if not safe_filename or safe_filename == ext:
        safe_filename = f"file_{int(time.time())}{ext}"
    if not safe_filename.lower().endswith(ext):
        safe_filename = safe_filename + ext
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ç¢ºä¿
    from config import KNOWLEDGE_BASE_DIR
    input_dir = Path(KNOWLEDGE_BASE_DIR) / "uploads"
    input_dir.mkdir(parents=True, exist_ok=True)
    
    base_name = Path(safe_filename).stem
    file_path = input_dir / safe_filename
    timestamp = int(time.time())
    if file_path.exists():
        file_path = input_dir / f"{base_name}_{timestamp}{ext}"
    
    try:
        content = await file.read()
        
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413, 
                detail=f"File too large. Maximum size is {MAX_FILE_SIZE // (1024*1024)}MB"
            )
        
        # file_storeã«ç™»éŒ² (è«–ç†ID = SHA-256å…ˆé ­16æ–‡å­—)
        import file_store
        content_type = "application/pdf" if ext == ".pdf" else f"image/{ext[1:]}"
        reg = file_store.register_file(
            original_name=filename,
            current_path=str(file_path),
            content=content,
            content_type=content_type
        )
        file_id = reg["id"]
        
        # PDFã¯IDåã§ã‚‚ä¿å­˜ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®å®‰å®šãƒ‘ã‚¹ï¼‰
        if ext == ".pdf":
            from config import PDF_STORAGE_DIR
            pdf_dir = Path(PDF_STORAGE_DIR)
            pdf_dir.mkdir(parents=True, exist_ok=True)
            pdf_save_path = pdf_dir / f"{file_id}.pdf"
            if not pdf_save_path.exists():
                with open(pdf_save_path, "wb") as f_pdf:
                    f_pdf.write(content)
        
        # å…ƒã®ãƒ‘ã‚¹ã«ã‚‚ä¿å­˜ï¼ˆOCR/åˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ï¼‰
        with open(file_path, "wb") as buffer:
            buffer.write(content)
        logger.info(f"File uploaded: {file_path}, Size: {len(content)} bytes, ID: {file_id}")
        
        # è‡ªå‹•å‡¦ç†é–‹å§‹ (PDFã®ã¿)
        if ext == ".pdf":
            from pipeline_manager import process_file_pipeline
            background_tasks.add_task(process_file_pipeline, str(file_path))

        return {
            "filename": file_path.name, 
            "status": "uploaded", 
            "path": str(file_path),
            "file_id": file_id,
            "original_name": filename,
            "message": "File uploaded successfully. Automatic classification will start shortly."
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Upload error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ========== PDF Delivery & File Info API ==========

@app.get("/api/pdf/{file_id}")
async def get_pdf(file_id: str):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªé…ä¿¡ï¼ˆfile_storeã‹ã‚‰è§£æ±ºã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Šï¼‰"""
    if not file_id.isalnum():
        raise HTTPException(status_code=400, detail="Invalid file_id")
    
    # 1. file_storeã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    try:
        import file_store
        file_info = file_store.get_file(file_id)
        if file_info:
            fp = Path(file_info["current_path"])
            if fp.exists():
                return FileResponse(fp, media_type="application/pdf",
                                   filename=file_info.get("original_name", fp.name))
    except Exception:
        pass
    
    # 2. PDF_STORAGE_DIRå†…ã®IDåãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from config import PDF_STORAGE_DIR
    target_path = Path(PDF_STORAGE_DIR) / f"{file_id}.pdf"
    if target_path.exists():
        return FileResponse(target_path, media_type="application/pdf")
    
    raise HTTPException(status_code=404, detail="PDF not found")


@app.get("/api/files/{file_id}/info")
async def get_file_info(file_id: str):
    """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ãƒ‘ã‚¹ã€åŒæœŸçŠ¶æ…‹ç­‰ï¼‰"""
    try:
        import file_store
        info = file_store.get_file(file_id)
        if not info:
            raise HTTPException(status_code=404, detail="File not found")
        return info
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tags")
async def get_tags():
    """åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚°ä¸€è¦§ã‚’å–å¾—"""
    try:
        import yaml
        base_dir = Path(".")
        rules_path = base_dir / "classification_rules.yaml"
        if not rules_path.exists():
            return {}
            
        with open(rules_path, 'r', encoding='utf-8') as f:
            rules = yaml.safe_load(f)
            
        return rules.get("available_tags", {})
    except Exception as e:
        logger.error(f"Failed to load tags: {e}")
        return {}

@app.get("/api/pdf/metadata/{file_id}")
async def get_pdf_metadata(file_id: str):
    """PDFãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    import pypdf
    from config import PDF_STORAGE_DIR
    
    if not file_id.isalnum():
         raise HTTPException(status_code=400, detail="Invalid file_id")

    target_path = Path(PDF_STORAGE_DIR) / f"{file_id}.pdf"
    
    if not target_path.exists():
        raise HTTPException(status_code=404, detail="PDF not found")
        
    try:
        reader = pypdf.PdfReader(target_path)
        return {
            "file_id": file_id,
            "page_count": len(reader.pages),
            "size_bytes": target_path.stat().st_size
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



# ========== è¨­å®šé–¢é€£ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==========

class GeminiKeyRequest(BaseModel):
    api_key: str

@app.get("/api/settings/gemini-key")
async def get_gemini_key():
    """è¨­å®šæ¸ˆã¿ã®Gemini APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ä¸€éƒ¨éš è”½ï¼‰"""
    api_key = os.environ.get("GEMINI_API_KEY", "")
    if not api_key:
        return {"api_key": "", "configured": False}
    
    # å‰å¾Œæ•°æ–‡å­—ã ã‘è¡¨ç¤º
    if len(api_key) > 8:
        masked = f"{api_key[:4]}...{api_key[-4:]}"
    else:
        masked = "****"
        
    return {"api_key": masked, "configured": True}

@app.post("/api/settings/gemini-key")
async def set_gemini_key(request: GeminiKeyRequest):
    """Gemini APIã‚­ãƒ¼ã‚’è¨­å®šãƒ»ä¿å­˜"""
    new_key = request.api_key.strip()
    if not new_key:
        raise HTTPException(status_code=400, detail="APIã‚­ãƒ¼ãŒç©ºã§ã™")
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    env_path = Path(".env")
    lines = []
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
    key_exists = False
    new_lines = []
    for line in lines:
        if line.strip().startswith("GEMINI_API_KEY="):
            new_lines.append(f"GEMINI_API_KEY={new_key}\n")
            key_exists = True
        else:
            new_lines.append(line)
            
    if not key_exists:
        if new_lines and not new_lines[-1].endswith('\n'):
            new_lines[-1] += '\n'
        new_lines.append(f"GEMINI_API_KEY={new_key}\n")
        
    with open(env_path, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)
        
    # ç’°å¢ƒå¤‰æ•°ã¨configã‚’æ›´æ–°
    os.environ["GEMINI_API_KEY"] = new_key
    import config
    config.GEMINI_API_KEY = new_key
    
    # genaiã‚’å†è¨­å®š
    import google.generativeai as genai
    genai.configure(api_key=new_key)
    
    return {"message": "APIã‚­ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ"}

@app.post("/api/settings/test-gemini")
async def test_gemini_key():
    """ç¾åœ¨ã®APIã‚­ãƒ¼ã§Geminiæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    import google.generativeai as genai
    import config
    
    if not config.GEMINI_API_KEY:
        raise HTTPException(status_code=400, detail="APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
    try:
        genai.configure(api_key=config.GEMINI_API_KEY)
        model = genai.GenerativeModel("gemini-1.5-flash") # è»½é‡ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
        response = model.generate_content("Hello, this is a connection test.")
        return {"success": True, "message": "æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ", "response": response.text[:50]}
    except Exception as e:
        return {"success": False, "message": f"æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

